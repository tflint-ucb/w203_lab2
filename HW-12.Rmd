---
title: "HW week 12"
author: "w203 teaching team"
subtitle: 'w203: Statistics for Data Science'

output:
  pdf_document: default
  html_document: default
---

```{r load packages, message = FALSE}
library(tidyverse)
library(ggplot2) 

library(sandwich)
library(stargazer)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r source functions from project, echo = FALSE}
source('./src/load_and_clean.R')
source('./src/get_robust_se.R')
```

```{r load data} 
d <- load_and_clean(input = 'videos.txt')
```
# Regression analysis of YouTube dataset

You want to explain how much the quality of a video affects the number of views it receives on social media. In a world where people can now buy followers and likes, would such an investment increase the number of views that their content receives?  **This is a causal question.** 

You will use a dataset created by Cheng, Dale and Liu at Simon Fraser University.  It includes observations about 9618 videos shared on YouTube.  Please see [this link](http://netsg.cs.sfu.ca/youtubedata/) for details about how the data was collected.

You will use the following variables:

- `views`: the number of views by YouTube users.
- `average_rating`: This is the average of the ratings that the video received, it is a renamed feature from `rate` that is provided in the original dataset. (Notice that this is different from `cout_of_ratings` which is a count of the total number of ratings that a video has received. 
- `length:` the duration of the video in seconds.

a. Perform a brief exploratory data analysis on the data to discover patterns, outliers, or wrong data entries and summarize your findings.

```{r conduct EDA in this chunk}
ggplot(d, aes(x=average_rating)) + geom_histogram(bins = 100)
yt_df<-d[!(d$average_rating==0),]

ggplot(yt_df, aes(x=views)) + geom_histogram(bins = 100)
ggplot(yt_df, aes(x=log(views))) + geom_histogram(bins = 100)
ggplot(yt_df, aes(x=length)) + geom_histogram(bins = 100)
ggplot(yt_df, aes(x=log(length))) + geom_histogram(bins = 100)


```

A lot of entries have a 0 for average rating, this seems unusual since Youtube did not have the option to leave such a rating. If we look at the table, we'll notice that this is because it received no ratings.

It would be a good idea to drop entries without ratings, as 0 will be interpreted as being of low quality, when in reality we don't have information about its quality.

Both views and lengths have some outliers with some very high values. 

b. Based on your EDA, select an appropriate variable transformation (if any) to apply to each of your three variables.  You will fit a model of the type,

$$
  f(\text{views}) = \beta_0 + \beta_1 g(\text{rate})  + \beta_3 h(\text{length})
$$ 

Where $f$, $g$ and $h$ are sensible transformations, which might include making *no* transformation. 

```{r fit a regression model here}
model <- lm(log(views) ~ average_rating + log(length), data=yt_df)

stargazer(
  model, 
  type = 'text', 
  se = list(get_robust_se(model))
)
```



c. Using diagnostic plots, background knowledge, and statistical tests, assess all five assumptions of the CLM. When an assumption is violated, state what response you will take.  As part of this process, you should decide what transformation (if any) to apply to each variable. Iterate against your model until your satisfied that at least four of the five assumption have been reasonably addressed. 

> 1. **IID Data:** We have a dataset that includes observations of about 9618 videos shared on YouTube. While we expect each sample's distribution to be identical we may not claim clean independence. Number of views on a video in a specific genre or interest area can influence views on other videos since they may get recommended more frequently.

> 2. **No Perfect Colinearity:** Our model ran without dropping variables which indicates that there are no variables that are perfectly colinear.

> 3. **Linear Conditional Expectation:** When we're looking to asses linear conditional expectation we want to look at the range of predicted values and errors or residuals. The model we chose does satisfy this assumption because we see a linear relationship in the plot. There is a fairly straight line near zero. But this same plot gives us some info about the next assumption on Homoskedastic Errors.


```{r code and plots assessing linear conditional expectation}
modf <- fortify(model)
ggplot(modf, aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth()
```

> 4. **Homoskedastic Errors:** We're using the same fitted vs. residual values plot which shows that errors are not evenly distrbuted from left to right and there is an increase in variation of error terms as we move right on the x-axis. This means there is presennce of homoscedasticity. Since we do have a large sample of well above 100 we are not as concerned with this issue since we'll be using ropbust standard errors that will produce correct or nominal standard errors in p-values. This may have to do with skewness that we saw in the data earlier when fitting the model.

```{r code and plots assessing homoskedastic errors}
modf <- fortify(model)
ggplot(modf, aes(x = .fitted, y = .resid)) + geom_point() + geom_smooth()

#should we do a Breuch Pegan test?
```

> 5. **Normally Distributed Errors:** To check for normal distribution in errors we look at the Normal Q-Q plot. When errors are normally distrbuted we'll see a straight line, which we do see in the plot below. There is small deviation in the tails but overall we don't see serious deviations from normality. This assumption is satisfied.

```{r}
plot(model, which=2)
```